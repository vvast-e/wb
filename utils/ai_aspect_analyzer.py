import re
import logging
from typing import List, Dict, Optional
import asyncio
import httpx
from openai import OpenAI
import os
from dotenv import load_dotenv
from datetime import datetime, timedelta
import time

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

logger = logging.getLogger(__name__)

class AIAspectAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∞—Å–ø–µ–∫—Ç–æ–≤ —Ç–æ–≤–∞—Ä–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ò–ò —á–µ—Ä–µ–∑ OpenRouter API —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö –∞—Å–ø–µ–∫—Ç–æ–≤"""
    
    def __init__(self):
        # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–æ—Ç–∞—Ü–∏–∏ API –∫–ª—é—á–µ–π OpenRouter –∏–∑ .env —Ñ–∞–π–ª–∞
        self.api_keys = [
            os.getenv('DEEPSEEK_TOKEN1'),
            os.getenv('DEEPSEEK_TOKEN2'),
            os.getenv('DEEPSEEK_TOKEN3'),
            os.getenv('DEEPSEEK_TOKEN4'),
            os.getenv('DEEPSEEK_TOKEN5')
        ]
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º None –∑–Ω–∞—á–µ–Ω–∏—è
        self.api_keys = [key for key in self.api_keys if key]
        
        if not self.api_keys:
            raise ValueError("–ù–µ –Ω–∞–π–¥–µ–Ω—ã API –∫–ª—é—á–∏ –¥–ª—è OpenRouter")
        
        self.current_key_index = 0
        self.client = None
        
        # –°–∏—Å—Ç–µ–º–∞ –∫–æ–Ω—Ç—Ä–æ–ª—è –ª–∏–º–∏—Ç–æ–≤
        self.request_timestamps = []  # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è –º–∏–Ω—É—Ç–Ω—ã—Ö –ª–∏–º–∏—Ç–æ–≤
        self.daily_request_counts = {i: 0 for i in range(len(self.api_keys))}  # –°—á–µ—Ç—á–∏–∫–∏ –¥–Ω–µ–≤–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ –∫–ª—é—á–∞–º
        self.last_request_dates = {i: None for i in range(len(self.api_keys))}  # –î–∞—Ç—ã –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ –∫–ª—é—á–∞–º
        
        # –õ–∏–º–∏—Ç—ã API
        self.MAX_REQUESTS_PER_MINUTE = 10  # –û–±—â–∏–π –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –º–∏–Ω—É—Ç—É
        self.MAX_REQUESTS_PER_DAY = 250     # –û–±—â–∏–π –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –¥–µ–Ω—å
        self.MINUTE_WINDOW = 60             # –û–∫–Ω–æ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö –¥–ª—è –º–∏–Ω—É—Ç–Ω–æ–≥–æ –ª–∏–º–∏—Ç–∞
        self.DAY_WINDOW = 86400             # –û–∫–Ω–æ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö –¥–ª—è –¥–Ω–µ–≤–Ω–æ–≥–æ –ª–∏–º–∏—Ç–∞
        
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã
        self.MAX_REVIEWS_PER_PROMPT = 50  # –£–º–µ–Ω—å—à–∞–µ–º –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        self.MAX_TOKENS_PER_REVIEW = 100  # –£–º–µ–Ω—å—à–∞–µ–º –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏
        self.MAX_TOTAL_TOKENS = 6000      # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        
        # –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏
        self.available_models = {
            "deepseek": "deepseek/deepseek-r1-0528-qwen3-8b:free",
            "qwen": "qwen/qwen-3-8b-chat",
            "gemma": "google/gemma-7b-it"
        }
        
        # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã
        self.prompts = {
            "creative_batch_analysis": """–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π {batch_size} –æ—Ç–∑—ã–≤–æ–≤ –∏ —Å–æ–∑–¥–∞–π –∞—Å–ø–µ–∫—Ç—ã.

–ü–†–ê–í–ò–õ–ê:
- –ò—Å–ø–æ–ª—å–∑—É–π –±–∞–∑–æ–≤—ã–µ –∞—Å–ø–µ–∫—Ç—ã: –¶–µ–Ω–∞, –ö–∞—á–µ—Å—Ç–≤–æ, –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å, –£–ø–∞–∫–æ–≤–∫–∞, –ó–∞–ø–∞—Ö
- –°–æ–∑–¥–∞–≤–∞–π –Ω–æ–≤—ã–µ –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤
- –ö–∞–∂–¥—ã–π –∞—Å–ø–µ–∫—Ç: –Ω–∞–∑–≤–∞–Ω–∏–µ, —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å (positive/negative), —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (0.1-1.0), –∫–∞—Ç–µ–≥–æ—Ä–∏—è

–§–û–†–ú–ê–¢:
```json
[
  {{
    "review_index": 0,
    "aspects": {{
      "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å": {{
        "sentiment": "positive",
        "confidence": 0.9,
        "evidence": ["–≤–æ–ª–æ—Å—ã —Ä–∞—Å—Ç—É—Ç"],
        "category": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å",
        "is_new_aspect": false
      }}
    }}
  }}
]```

–û–¢–ó–´–í–´:
{reviews_batch}"""
        }
        
        self._init_client()

    def _check_rate_limits(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ª–∏–º–∏—Ç—ã API –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç True –µ—Å–ª–∏ –º–æ–∂–Ω–æ –¥–µ–ª–∞—Ç—å –∑–∞–ø—Ä–æ—Å"""
        current_time = time.time()
        
        # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ (—Å—Ç–∞—Ä—à–µ 1 –º–∏–Ω—É—Ç—ã)
        self.request_timestamps = [ts for ts in self.request_timestamps 
                                 if current_time - ts < self.MINUTE_WINDOW]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω—É—Ç–Ω—ã–π –ª–∏–º–∏—Ç
        if len(self.request_timestamps) >= self.MAX_REQUESTS_PER_MINUTE:
            logger.warning(f"–ü—Ä–µ–≤—ã—à–µ–Ω –º–∏–Ω—É—Ç–Ω—ã–π –ª–∏–º–∏—Ç: {len(self.request_timestamps)} –∑–∞–ø—Ä–æ—Å–æ–≤ –∑–∞ –º–∏–Ω—É—Ç—É")
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–Ω–µ–≤–Ω–æ–π –ª–∏–º–∏—Ç –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –∫–ª—é—á–∞
        if self.daily_request_counts[self.current_key_index] >= self.MAX_REQUESTS_PER_DAY:
            logger.warning(f"–ü—Ä–µ–≤—ã—à–µ–Ω –¥–Ω–µ–≤–Ω–æ–π –ª–∏–º–∏—Ç –¥–ª—è –∫–ª—é—á–∞ {self.current_key_index + 1}")
            return False
        
        return True
    
    def _wait_for_rate_limit(self) -> float:
        """–ñ–¥–µ—Ç –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –¥–æ—Å—Ç—É–ø–Ω–æ–≥–æ —Å–ª–æ—Ç–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è"""
        current_time = time.time()
        
        # –ï—Å–ª–∏ –ø—Ä–µ–≤—ã—à–µ–Ω –º–∏–Ω—É—Ç–Ω—ã–π –ª–∏–º–∏—Ç, –∂–¥–µ–º –¥–æ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è —Å–ª–æ—Ç–∞
        if len(self.request_timestamps) >= self.MAX_REQUESTS_PER_MINUTE:
            oldest_timestamp = min(self.request_timestamps)
            wait_time = self.MINUTE_WINDOW - (current_time - oldest_timestamp) + 1
            logger.info(f"–ñ–¥–µ–º {wait_time:.1f} —Å–µ–∫—É–Ω–¥ –¥–æ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è –º–∏–Ω—É—Ç–Ω–æ–≥–æ —Å–ª–æ—Ç–∞")
            return wait_time
        
        # –ï—Å–ª–∏ –ø—Ä–µ–≤—ã—à–µ–Ω –¥–Ω–µ–≤–Ω–æ–π –ª–∏–º–∏—Ç –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –∫–ª—é—á–∞, –∏—â–µ–º —Å–ª–µ–¥—É—é—â–∏–π –¥–æ—Å—Ç—É–ø–Ω—ã–π
        if self.daily_request_counts[self.current_key_index] >= self.MAX_REQUESTS_PER_DAY:
            # –ò—â–µ–º –∫–ª—é—á —Å –¥–æ—Å—Ç—É–ø–Ω—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏
            for i in range(len(self.api_keys)):
                if self.daily_request_counts[i] < self.MAX_REQUESTS_PER_DAY:
                    logger.info(f"–ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ –∫–ª—é—á {i + 1} (–∑–∞–ø—Ä–æ—Å–æ–≤: {self.daily_request_counts[i]})")
                    self.current_key_index = i
                    self._init_client()
                    return 0
            
            # –ï—Å–ª–∏ –≤—Å–µ –∫–ª—é—á–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã, –∂–¥–µ–º –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –¥–Ω—è
            wait_time = self.DAY_WINDOW - (current_time % self.DAY_WINDOW)
            logger.warning(f"–í—Å–µ –∫–ª—é—á–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã, –∂–¥–µ–º {wait_time/3600:.1f} —á–∞—Å–æ–≤ –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –¥–Ω—è")
            return wait_time
        
        return 0
    
    def _update_request_counters(self):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å—á–µ—Ç—á–∏–∫–∏ –∑–∞–ø—Ä–æ—Å–æ–≤"""
        current_time = time.time()
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â—É—é –≤—Ä–µ–º–µ–Ω–Ω—É—é –º–µ—Ç–∫—É
        self.request_timestamps.append(current_time)
        
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –¥–Ω–µ–≤–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –∫–ª—é—á–∞
        self.daily_request_counts[self.current_key_index] += 1
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞—Ç—É –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
        self.last_request_dates[self.current_key_index] = current_time
        
        logger.debug(f"–ö–ª—é—á {self.current_key_index + 1}: –∑–∞–ø—Ä–æ—Å–æ–≤ —Å–µ–≥–æ–¥–Ω—è {self.daily_request_counts[self.current_key_index]}")
    
    def _reset_daily_counters_if_needed(self):
        """–°–±—Ä–∞—Å—ã–≤–∞–µ—Ç –¥–Ω–µ–≤–Ω—ã–µ —Å—á–µ—Ç—á–∏–∫–∏ –µ—Å–ª–∏ –ø—Ä–æ—à–µ–ª –¥–µ–Ω—å"""
        current_time = time.time()
        
        for key_index in range(len(self.api_keys)):
            last_date = self.last_request_dates[key_index]
            if last_date and (current_time - last_date) >= self.DAY_WINDOW:
                self.daily_request_counts[key_index] = 0
                logger.info(f"–°–±—Ä–æ—à–µ–Ω –¥–Ω–µ–≤–Ω–æ–π —Å—á–µ—Ç—á–∏–∫ –¥–ª—è –∫–ª—é—á–∞ {key_index + 1}")
    
    def get_rate_limit_status(self) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å –ª–∏–º–∏—Ç–æ–≤ API"""
        current_time = time.time()
        
        # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
        self.request_timestamps = [ts for ts in self.request_timestamps 
                                 if current_time - ts < self.MINUTE_WINDOW]
        
        return {
            "current_key": self.current_key_index + 1,
            "requests_last_minute": len(self.request_timestamps),
            "max_requests_per_minute": self.MAX_REQUESTS_PER_MINUTE,
            "daily_counts": {f"key_{i+1}": count for i, count in self.daily_request_counts.items()},
            "max_requests_per_day": self.MAX_REQUESTS_PER_DAY,
            "can_make_request": self._check_rate_limits()
        }

    async def analyze_reviews(self, reviews: List[str], product_name: str = "") -> Dict[str, List[str]]:
        """–ê–Ω–∞–ª–∏–∑ –æ—Ç–∑—ã–≤–æ–≤ –∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–ª–æ–≤–∞—Ä–µ–π –∞—Å–ø–µ–∫—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é –ò–ò"""
        try:
            # –†–∞–∑–±–∏–≤–∞–µ–º –æ—Ç–∑—ã–≤—ã –Ω–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –±–∞—Ç—á–∏
            review_batches = self._split_reviews_into_batches(reviews)
            
            all_aspects = []
            for batch in review_batches:
                # –§–æ—Ä–º–∏—Ä—É–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –±–∞—Ç—á–∞
                reviews_text = "\n".join(batch)
                batch_aspects = await self._generate_adaptive_dictionary(reviews_text, product_name, len(batch))
                all_aspects.extend(batch_aspects)
            
            # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏ –∏–∑ –≤—Å–µ—Ö –∞—Å–ø–µ–∫—Ç–æ–≤
            no_duplicates_dict = await self._remove_duplicates_ai(all_aspects, product_name)
            
            # –£–±–∏—Ä–∞–µ–º —Å–∏–Ω–æ–Ω–∏–º—ã
            no_synonyms_dict = await self._remove_synonyms_ai(no_duplicates_dict, product_name)
            
            return {
                "general_dictionary": all_aspects,
                "no_duplicates_dictionary": no_duplicates_dict,
                "no_synonyms_dictionary": no_synonyms_dict
            }
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –æ—Ç–∑—ã–≤–æ–≤ —Å –ò–ò: {e}")
            raise

    async def analyze_reviews_with_dynamic_aspects(self, reviews: List[str], product_name: str = "") -> List[Dict]:
        """–ê–Ω–∞–ª–∏–∑ –æ—Ç–∑—ã–≤–æ–≤ —Å —Å–æ–∑–¥–∞–Ω–∏–µ–º –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö –∞—Å–ø–µ–∫—Ç–æ–≤"""
        try:
            # –†–∞–∑–±–∏–≤–∞–µ–º –æ—Ç–∑—ã–≤—ã –Ω–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –±–∞—Ç—á–∏
            review_batches = self._split_reviews_into_batches(reviews)
            
            all_results = []
            for batch in review_batches:
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –±–∞—Ç—á —Å —Å–æ–∑–¥–∞–Ω–∏–µ–º –Ω–æ–≤—ã—Ö –∞—Å–ø–µ–∫—Ç–æ–≤
                batch_results = await self._analyze_batch_with_dynamic_aspects(batch, product_name, len(batch))
                all_results.extend(batch_results)
            
            return all_results
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –æ—Ç–∑—ã–≤–æ–≤ —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º–∏ –∞—Å–ø–µ–∫—Ç–∞–º–∏: {e}")
            raise

    async def analyze_reviews_safely_with_scheduler(self, reviews: List[str], product_name: str = "", 
                                                  max_batches_per_hour: int = 20) -> List[Dict]:
        """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤ –æ—Ç–∑—ã–≤–æ–≤ —Å –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–æ–º –∏ –∫–æ–Ω—Ç—Ä–æ–ª–µ–º –ª–∏–º–∏—Ç–æ–≤"""
        try:
            logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ {len(reviews)} –æ—Ç–∑—ã–≤–æ–≤")
            
            # –†–∞–∑–±–∏–≤–∞–µ–º –æ—Ç–∑—ã–≤—ã –Ω–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –±–∞—Ç—á–∏
            review_batches = self._split_reviews_into_batches(reviews)
            total_batches = len(review_batches)
            
            logger.info(f"üìä –†–∞–∑–±–∏—Ç–æ –Ω–∞ {total_batches} –±–∞—Ç—á–µ–π –ø–æ {self.MAX_REVIEWS_PER_PROMPT} –æ—Ç–∑—ã–≤–æ–≤")
            
            all_results = []
            processed_batches = 0
            start_time = time.time()
            
            for batch_index, batch in enumerate(review_batches, 1):
                try:
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å –ª–∏–º–∏—Ç–æ–≤
                    status = self.get_rate_limit_status()
                    current_key = status['current_key']
                    daily_count = status['daily_counts'][f'key_{current_key}']
                    logger.info(f"üìà –°—Ç–∞—Ç—É—Å –ª–∏–º–∏—Ç–æ–≤: –∫–ª—é—á {current_key}, "
                              f"–∑–∞–ø—Ä–æ—Å–æ–≤ –∑–∞ –º–∏–Ω—É—Ç—É: {status['requests_last_minute']}/{status['max_requests_per_minute']}, "
                              f"–∑–∞–ø—Ä–æ—Å–æ–≤ –∑–∞ –¥–µ–Ω—å: {daily_count}/{status['max_requests_per_day']}")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç—ã –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –±–∞—Ç—á–∞
                    if not self._check_rate_limits():
                        wait_time = self._wait_for_rate_limit()
                        if wait_time > 0:
                            logger.info(f"‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ {wait_time:.1f} —Å–µ–∫—É–Ω–¥ –¥–ª—è —Å–æ–±–ª—é–¥–µ–Ω–∏—è –ª–∏–º–∏—Ç–æ–≤...")
                            await asyncio.sleep(wait_time)
                    
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –±–∞—Ç—á
                    logger.info(f"üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ {batch_index}/{total_batches} ({len(batch)} –æ—Ç–∑—ã–≤–æ–≤)")
                    batch_start_time = time.time()
                    
                    batch_results = await self._analyze_batch_with_dynamic_aspects(batch, product_name, len(batch))
                    all_results.extend(batch_results)
                    
                    batch_time = time.time() - batch_start_time
                    processed_batches += 1
                    
                    logger.info(f"‚úÖ –ë–∞—Ç—á {batch_index} –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∑–∞ {batch_time:.1f} —Å–µ–∫—É–Ω–¥")
                    
                    # –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫: –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞—Ç—á–µ–π –≤ —á–∞—Å
                    if processed_batches >= max_batches_per_hour:
                        elapsed_hours = (time.time() - start_time) / 3600
                        if elapsed_hours < 1.0:
                            wait_time = 3600 - (time.time() - start_time)
                            logger.info(f"‚è∞ –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç {max_batches_per_hour} –±–∞—Ç—á–µ–π –≤ —á–∞—Å, "
                                      f"–æ–∂–∏–¥–∞–Ω–∏–µ {wait_time/60:.1f} –º–∏–Ω—É—Ç...")
                            await asyncio.sleep(wait_time)
                            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫–∏ –¥–ª—è –Ω–æ–≤–æ–≥–æ —á–∞—Å–∞
                            processed_batches = 0
                            start_time = time.time()
                    
                    # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                    if batch_index < total_batches:
                        await asyncio.sleep(2)
                    
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –±–∞—Ç—á–∞ {batch_index}: {e}")
                    # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å —Å–ª–µ–¥—É—é—â–∏–º –±–∞—Ç—á–µ–º
                    continue
            
            total_time = time.time() - start_time
            logger.info(f"üéâ –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: {len(all_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∑–∞ {total_time/60:.1f} –º–∏–Ω—É—Ç")
            
            return all_results
            
        except Exception as e:
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ–º –∞–Ω–∞–ª–∏–∑–µ: {e}")
            raise

    async def analyze_single_review(self, review_text: str, rating: int) -> Dict[str, List[str]]:
        """–ê–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ –æ—Ç–∑—ã–≤–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∞—Å–ø–µ–∫—Ç–æ–≤ —Å —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å—é —Å –ø–æ–º–æ—â—å—é –ò–ò"""
        try:
            prompt = self.prompts["single_review_enhanced"].format(
                review_text=review_text,
                rating=rating
            )
            
            response = await self._call_ai_model(prompt, "deepseek")
            
            # –ü–∞—Ä—Å–∏–º JSON –æ—Ç–≤–µ—Ç
            try:
                import json
                import re
                
                # –£–±–∏—Ä–∞–µ–º markdown –±–ª–æ–∫–∏ –∫–æ–¥–∞ –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
                cleaned_response = response.strip()
                
                # –ò—â–µ–º JSON –≤–Ω—É—Ç—Ä–∏ markdown –±–ª–æ–∫–æ–≤ –∫–æ–¥–∞
                json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', cleaned_response, re.DOTALL)
                if json_match:
                    json_str = json_match.group(1)
                else:
                    # –ï—Å–ª–∏ –Ω–µ—Ç markdown –±–ª–æ–∫–æ–≤, –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ JSON –Ω–∞–ø—Ä—è–º—É—é
                    json_match = re.search(r'\{.*\}', cleaned_response, re.DOTALL)
                    if json_match:
                        json_str = json_match.group(0)
                    else:
                        json_str = cleaned_response
                
                # –ü–∞—Ä—Å–∏–º JSON
                result = json.loads(json_str)
                aspects = result.get("aspects", {})
                
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                positive_aspects = []
                negative_aspects = []
                
                for aspect_name, aspect_data in aspects.items():
                    sentiment = aspect_data.get("sentiment", "neutral")
                    if sentiment == "positive":
                        positive_aspects.append(aspect_name)
                    elif sentiment == "negative":
                        negative_aspects.append(aspect_name)
                
                return {
                    "positive": positive_aspects[:3],
                    "negative": negative_aspects[:3]
                }
            except json.JSONDecodeError as e:
                logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –æ—Ç–≤–µ—Ç: {response}")
                logger.error(f"–û—à–∏–±–∫–∞ JSON: {e}")
                return {"positive": [], "negative": []}
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –æ–¥–Ω–æ–≥–æ –æ—Ç–∑—ã–≤–∞ —Å –ò–ò: {e}")
            return {"positive": [], "negative": []}

    async def generate_custom_dictionary(self, aspects: List[str], synonym_journal: List[str] = None) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–∞—Å—Ç–æ–º–Ω–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è –∞—Å–ø–µ–∫—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é –ò–ò"""
        try:
            if not synonym_journal:
                return aspects
            
            return await self._remove_synonyms_ai(aspects, "", synonym_journal)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–∞—Å—Ç–æ–º–Ω–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è —Å –ò–ò: {e}")
            return aspects

    async def _generate_adaptive_dictionary(self, reviews_text: str, product_name: str, batch_size: int) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è –∞—Å–ø–µ–∫—Ç–æ–≤"""
        prompt = self.prompts["creative_batch_analysis"].format(
            product_name=product_name or "—Ç–æ–≤–∞—Ä",
            reviews=reviews_text,
            batch_size=batch_size
        )
        
        response = await self._call_ai_model(prompt, "deepseek")
        return self._parse_aspects_response(response)

    async def _analyze_batch_with_dynamic_aspects(self, reviews: List[str], product_name: str, batch_size: int) -> List[Dict]:
        """–ê–Ω–∞–ª–∏–∑ –±–∞—Ç—á–∞ —Å —Å–æ–∑–¥–∞–Ω–∏–µ–º –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö –∞—Å–ø–µ–∫—Ç–æ–≤"""
        prompt = self.prompts["creative_batch_analysis"].format(
            product_name=product_name or "—Ç–æ–≤–∞—Ä",
            reviews_batch="\n".join(reviews),
            batch_size=batch_size
        )
        
        response = await self._call_ai_model(prompt, "deepseek")
        return self._parse_dynamic_aspects_response(response)

    async def _remove_duplicates_ai(self, aspects: List[str], product_name: str) -> List[str]:
        """–£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è –∞—Å–ø–µ–∫—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é –ò–ò"""
        if not aspects:
            return []
        
        aspects_text = "\n".join(aspects)
        prompt = f"""–£–±–µ—Ä–∏ –¥—É–±–ª–∏–∫–∞—Ç—ã –∏–∑ —Å–ø–∏—Å–∫–∞ –∞—Å–ø–µ–∫—Ç–æ–≤ –¥–ª—è —Ç–æ–≤–∞—Ä–∞ "{product_name}".
        
        –ê—Å–ø–µ–∫—Ç—ã: {aspects_text}
        
        –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã, —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏ —Å—Ç—Ä–æ–∫."""
        
        response = await self._call_ai_model(prompt, "deepseek")
        return self._parse_aspects_response(response)

    async def _remove_synonyms_ai(self, aspects: List[str], product_name: str, synonym_journal: List[str] = None) -> List[str]:
        """–£–¥–∞–ª–µ–Ω–∏–µ —Å–∏–Ω–æ–Ω–∏–º–æ–≤ —Å –ø–æ–º–æ—â—å—é –ò–ò"""
        if not aspects:
            return []
        
        if not synonym_journal:
            return aspects
        
        aspects_text = "\n".join(aspects)
        journal_text = "\n".join(synonym_journal)
        
        prompt = f"""–£–±–µ—Ä–∏ —Å–∏–Ω–æ–Ω–∏–º—ã –∏–∑ —Å–ø–∏—Å–∫–∞ –∞—Å–ø–µ–∫—Ç–æ–≤ –¥–ª—è —Ç–æ–≤–∞—Ä–∞ "{product_name}".
        
        –ñ—É—Ä–Ω–∞–ª —Å–∏–Ω–æ–Ω–∏–º–æ–≤: {journal_text}
        –ê—Å–ø–µ–∫—Ç—ã: {aspects_text}
        
        –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã –±–µ–∑ —Å–∏–Ω–æ–Ω–∏–º–æ–≤."""
        
        response = await self._call_ai_model(prompt, "deepseek")
        return self._parse_aspects_response(response)

    async def _call_ai_model(self, prompt: str, model_name: str = "deepseek") -> str:
        """–í—ã–∑–æ–≤ –ò–ò –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ OpenRouter API —Å —É–º–Ω—ã–º –∫–æ–Ω—Ç—Ä–æ–ª–µ–º –ª–∏–º–∏—Ç–æ–≤ –∏ —Ä–æ—Ç–∞—Ü–∏–µ–π –∫–ª—é—á–µ–π"""
        max_retries = len(self.api_keys)
        
        for attempt in range(max_retries):
            try:
                # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –¥–Ω–µ–≤–Ω—ã–µ —Å—á–µ—Ç—á–∏–∫–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                self._reset_daily_counters_if_needed()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç—ã –ø–µ—Ä–µ–¥ –∑–∞–ø—Ä–æ—Å–æ–º
                if not self._check_rate_limits():
                    wait_time = self._wait_for_rate_limit()
                    if wait_time > 0:
                        logger.info(f"‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ {wait_time:.1f} —Å–µ–∫—É–Ω–¥ –¥–ª—è —Å–æ–±–ª—é–¥–µ–Ω–∏—è –ª–∏–º–∏—Ç–æ–≤...")
                        await asyncio.sleep(wait_time)
                        continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç—ã –µ—â–µ —Ä–∞–∑ –ø–æ—Å–ª–µ –æ–∂–∏–¥–∞–Ω–∏—è
                if not self._check_rate_limits():
                    logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±–ª—é—Å—Ç–∏ –ª–∏–º–∏—Ç—ã API –ø–æ—Å–ª–µ –æ–∂–∏–¥–∞–Ω–∏—è")
                    continue
                
                model = self.available_models.get(model_name, self.available_models["deepseek"])
                
                logger.info(f"üöÄ API –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ –∫–ª—é—á {self.current_key_index + 1} (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1})")
                
                response = self.client.chat.completions.create(
                    model=model,
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=4000,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –±–∞—Ç—á–µ–π
                    temperature=0.7
                )
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫–∏ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
                self._update_request_counters()
                
                logger.info(f"‚úÖ API –∑–∞–ø—Ä–æ—Å —É—Å–ø–µ—à–µ–Ω —á–µ—Ä–µ–∑ –∫–ª—é—á {self.current_key_index + 1}")
                return response.choices[0].message.content.strip()
                
            except Exception as e:
                error_msg = str(e).lower()
                logger.warning(f"‚ùå –û—à–∏–±–∫–∞ API –∫–ª—é—á–∞ {self.current_key_index + 1}: {e}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –æ—à–∏–±–∫–∏ –¥–ª—è —Ä–æ—Ç–∞—Ü–∏–∏ –∫–ª—é—á–∞
                if any(keyword in error_msg for keyword in ['rate limit', '429', 'quota', 'limit', 'token']):
                    logger.info(f"üîÑ –ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –¥–ª—è –∫–ª—é—á–∞ {self.current_key_index + 1}, –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π")
                    self._init_client()  # –†–æ—Ç–∞—Ü–∏—è –∫–ª—é—á–∞
                else:
                    # –î–ª—è –¥—Ä—É–≥–∏—Ö –æ—à–∏–±–æ–∫ —Ç–æ–∂–µ –ø—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â–∏–π –∫–ª—é—á
                    logger.info(f"üîÑ –û—à–∏–±–∫–∞ API, –ø—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â–∏–π –∫–ª—é—á")
                    self._init_client()
                
                if attempt == max_retries - 1:
                    raise Exception(f"–í—Å–µ API –∫–ª—é—á–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã. –ü–æ—Å–ª–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞: {e}")
        
        raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å –ø–æ—Å–ª–µ –≤—Å–µ—Ö –ø–æ–ø—ã—Ç–æ–∫")

    def _parse_aspects_response(self, response: str) -> List[str]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –ò–ò –≤ —Å–ø–∏—Å–æ–∫ –∞—Å–ø–µ–∫—Ç–æ–≤"""
        try:
            import re
            
            # –£–±–∏—Ä–∞–µ–º markdown –±–ª–æ–∫–∏ –∫–æ–¥–∞ –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
            cleaned_response = response.strip()
            
            # –ò—â–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≤–Ω—É—Ç—Ä–∏ markdown –±–ª–æ–∫–æ–≤ –∫–æ–¥–∞
            code_match = re.search(r'```(?:.*?)?\s*([\s\S]*?)\s*```', cleaned_response, re.DOTALL)
            if code_match:
                cleaned_response = code_match.group(1)
            
            # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ —Å—Ç—Ä–æ–∫–∞–º –∏ –æ—á–∏—â–∞–µ–º
            aspects = []
            for line in cleaned_response.split('\n'):
                line = line.strip()
                if line and not line.startswith('#') and not line.startswith('-'):
                    # –£–±–∏—Ä–∞–µ–º –Ω—É–º–µ—Ä–∞—Ü–∏—é –∏ –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã
                    line = re.sub(r'^\d+\.?\s*', '', line)
                    line = re.sub(r'^[-‚Ä¢*]\s*', '', line)
                    if line:
                        aspects.append(line)
            
            return aspects[:30]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 30 –∞—Å–ø–µ–∫—Ç–æ–≤
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –æ—Ç–≤–µ—Ç–∞ –ò–ò: {e}")
            return []

    def _parse_dynamic_aspects_response(self, response: str) -> List[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –ò–ò —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º–∏ –∞—Å–ø–µ–∫—Ç–∞–º–∏"""
        try:
            import json
            import re
            
            # –£–±–∏—Ä–∞–µ–º markdown –±–ª–æ–∫–∏ –∫–æ–¥–∞ –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
            cleaned_response = response.strip()
            
            # –ò—â–µ–º JSON –≤–Ω—É—Ç—Ä–∏ markdown –±–ª–æ–∫–æ–≤ –∫–æ–¥–∞
            json_match = re.search(r'```(?:json)?\s*(\[.*?\])\s*```', cleaned_response, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                # –ï—Å–ª–∏ –Ω–µ—Ç markdown –±–ª–æ–∫–æ–≤, –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ JSON –Ω–∞–ø—Ä—è–º—É—é
                json_match = re.search(r'\[.*\]', cleaned_response, re.DOTALL)
                if json_match:
                    json_str = json_match.group(0)
                else:
                    # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –Ω–∞—á–∞–ª–æ JSON –º–∞—Å—Å–∏–≤–∞
                    start_match = re.search(r'\[', cleaned_response)
                    if start_match:
                        # –ë–µ—Ä–µ–º –≤—Å–µ —á—Ç–æ –µ—Å—Ç—å –ø–æ—Å–ª–µ –æ—Ç–∫—Ä—ã–≤–∞—é—â–µ–π —Å–∫–æ–±–∫–∏
                        json_str = cleaned_response[start_match.start():]
                        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∑–∞–∫—Ä—ã–≤–∞—é—â—É—é —Å–∫–æ–±–∫—É
                        bracket_count = 0
                        for i, char in enumerate(json_str):
                            if char == '[':
                                bracket_count += 1
                            elif char == ']':
                                bracket_count -= 1
                                if bracket_count == 0:
                                    json_str = json_str[:i+1]
                                    break
                    else:
                        json_str = cleaned_response
            
            # –ü–∞—Ä—Å–∏–º JSON
            try:
                result = json.loads(json_str)
                return result
            except json.JSONDecodeError:
                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å, –ø—Ä–æ–±—É–µ–º –∏—Å–ø—Ä–∞–≤–∏—Ç—å –æ–±—Ä–µ–∑–∞–Ω–Ω—ã–π JSON
                logger.warning("JSON –æ–±—Ä–µ–∑–∞–Ω, –ø—ã—Ç–∞–µ–º—Å—è –∏—Å–ø—Ä–∞–≤–∏—Ç—å...")
                fixed_json = self._fix_truncated_json(json_str)
                if fixed_json:
                    return json.loads(fixed_json)
                else:
                    raise json.JSONDecodeError("–ù–µ —É–¥–∞–ª–æ—Å—å –∏—Å–ø—Ä–∞–≤–∏—Ç—å –æ–±—Ä–µ–∑–∞–Ω–Ω—ã–π JSON", json_str, 0)
            
        except json.JSONDecodeError as e:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –æ—Ç–≤–µ—Ç —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º–∏ –∞—Å–ø–µ–∫—Ç–∞–º–∏: {response[:500]}...")
            logger.error(f"–û—à–∏–±–∫–∞ JSON: {e}")
            return []
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –æ—Ç–≤–µ—Ç–∞ —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º–∏ –∞—Å–ø–µ–∫—Ç–∞–º–∏: {e}")
            return []

    def _fix_truncated_json(self, json_str: str) -> Optional[str]:
        """–ü—ã—Ç–∞–µ—Ç—Å—è –∏—Å–ø—Ä–∞–≤–∏—Ç—å –æ–±—Ä–µ–∑–∞–Ω–Ω—ã–π JSON"""
        try:
            # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã –≤ –∫–æ–Ω—Ü–µ
            json_str = json_str.rstrip(', \n\r\t')
            
            # –ï—Å–ª–∏ JSON –æ–±—Ä—ã–≤–∞–µ—Ç—Å—è –Ω–∞ –æ–±—ä–µ–∫—Ç–µ, –∑–∞–∫—Ä—ã–≤–∞–µ–º –µ–≥–æ
            if json_str.endswith('"'):
                json_str += '}'
            elif json_str.endswith('"}'):
                pass  # —É–∂–µ –∑–∞–∫—Ä—ã—Ç
            elif json_str.endswith('"}}'):
                pass  # —É–∂–µ –∑–∞–∫—Ä—ã—Ç
            elif json_str.endswith('"}},'):
                json_str = json_str.rstrip(',') + '}'
            elif json_str.endswith('"}}'):
                pass  # —É–∂–µ –∑–∞–∫—Ä—ã—Ç
            else:
                # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø–æ–ª–Ω—ã–π –æ–±—ä–µ–∫—Ç
                last_complete = re.search(r'\{[^{}]*"}[^{}]*$', json_str)
                if last_complete:
                    json_str = json_str[:last_complete.end()]
            
            # –ó–∞–∫—Ä—ã–≤–∞–µ–º –º–∞—Å—Å–∏–≤ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if not json_str.endswith(']'):
                json_str += ']'
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å
            json.loads(json_str)
            return json_str
            
        except:
            return None

    def _split_reviews_into_batches(self, reviews: List[str]) -> List[List[str]]:
        """–†–∞–∑–±–∏–≤–∞–µ—Ç –æ—Ç–∑—ã–≤—ã –Ω–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –±–∞—Ç—á–∏ —Å —É—á–µ—Ç–æ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π —Ç–æ–∫–µ–Ω–æ–≤"""
        if len(reviews) <= self.MAX_REVIEWS_PER_PROMPT:
            return [reviews]
        
        batches = []
        current_batch = []
        current_tokens = 0
        
        for review in reviews:
            # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤ (1 —Å–ª–æ–≤–æ ‚âà 1.3 —Ç–æ–∫–µ–Ω–∞)
            review_tokens = len(review.split()) * 1.3
            
            if (current_tokens + review_tokens > self.MAX_TOTAL_TOKENS or 
                len(current_batch) >= self.MAX_REVIEWS_PER_PROMPT):
                if current_batch:
                    batches.append(current_batch)
                current_batch = [review]
                current_tokens = review_tokens
            else:
                current_batch.append(review)
                current_tokens += review_tokens
        
        if current_batch:
            batches.append(current_batch)
        
        logger.info(f"–†–∞–∑–±–∏—Ç–æ {len(reviews)} –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞ {len(batches)} –±–∞—Ç—á–µ–π")
        return batches

    def _init_client(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ OpenAI —Å —Ä–æ—Ç–∞—Ü–∏–µ–π API –∫–ª—é—á–µ–π"""
        # –ù–µ —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏, —Ç–æ–ª—å–∫–æ –ø—Ä–∏ —Ä–æ—Ç–∞—Ü–∏–∏
        if not hasattr(self, '_initialized'):
            self._initialized = True
            self.current_key_index = 0
        else:
            # –†–æ—Ç–∞—Ü–∏—è –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –∫–ª—é—á
            self.current_key_index = (self.current_key_index + 1) % len(self.api_keys)
        
        self.client = OpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=self.api_keys[self.current_key_index]
        )
        logger.info(f"üîë –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è API –∫–ª—é—á: {self.current_key_index + 1} ({self.api_keys[self.current_key_index][:8]}...)")

# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –ò–ò-–∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
try:
    ai_aspect_analyzer = AIAspectAnalyzer()
    logger.info("–ò–ò-–∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º–∏ –∞—Å–ø–µ–∫—Ç–∞–º–∏ —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
except Exception as e:
    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ò–ò-–∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä: {e}")
    ai_aspect_analyzer = None
